\documentclass[twocolumn, a4paper]{hcresume}

% 日本語処理のためのパッケージ
\usepackage{otf}
\usepackage{hyperref}
\usepackage[dvipdfmx]{pxjahyper}
\usepackage[dvipdfmx]{graphicx}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{txfonts}
\usepackage{color}
\usepackage{BoldGothic4fig}
\usepackage{subcaption}
\usepackage{float}
\usepackage{here}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\tiny,
  numbers=none,
  frame=none,
  breaklines=true,
  breakindent=0pt,
  postbreak=,
  prebreak=
}
\newfloat{lstfloat}{htbp}{lop}
\floatname{lstfloat}{Listing}
\def\lstfloatautorefname{Listing}


\hcheader{MIプログラム 卒業研究発表会}
\title{\bf 精緻化した受験者プロフィールを用いた \\ 大規模言語モデルに基づく仮想受験者}
\author{2020029　山羽　亨}
\supervisor{指導教員 宇都 雅輝 准教授}

\begin{document}
\maketitle
\pagestyle{empty}
\thispagestyle{empty}
\section{はじめに}

この章では，本研究の仮想受験者モデル研究の背景と課題を述べ，既存研究の限界を指摘した上で，先行研究の貢献と課題を示し，本研究の目的と位置付け，結果の概要を示す．

\subsection{研究背景と課題}

この節では，本研究の背景として実際の教育現場における項目特性推定の重要性と課題についてのべる．

\subsection{既存研究の限界}

この節では，課題解決のために考案された教師あり学習に基づく手法と，QAシステムに基づく手法の概要を説明し，それぞれに共通する訓練データ，項目反応データに関する課題を足がかりとして，先行研究のメリットと限界を述べる．

\subsection{本研究の目的と位置付け}

この節では，前の2つの節を踏まえて，本研究の目的と位置付け（先行研究の課題のうち解決を試みた点の明示）を述べ，結果とともに，このアプローチの限界の概要を示す．

% 近年ニーズが高まっている個別適応的な学習支援やCBT(Computer Based Testing)などに基づく高度なテスト運用においては，難易度や識別力などの特性が既知のテスト問題（以降，項目と呼ぶ）が重要な役割を果たす．
% 例えば，知的学習支援システムでは，学習者の能力にあった難易度の項目を適応的に出題する機能が重要要件の一つとなるが，この実現のためには各項目の難易度が既知である必要がある．
% またCBTでは，異なる項目群で構成されるにも関わらず統計的な性質が類似したテスト版を多数構成して活用することで，
% 高精度な能力測定を担保しつつ不正防止や試験結果の年度間比較などが実現されるが，このためにも各項目の特性が既知である必要がある．
% そのため，これらの場面では，予め目標の母集団から受験者や学習者(以降，受験者に統一)を集めて関心下の項目を出題し，得られた反応データから項目特性を推定する「事前テスト」が一般に行われる．
% しかし，事前テストの実施には多大なコストがかかる上に項目内容の漏洩リスクも生じる．

% この問題を解決するために，自然言語処理技術を用いて問題文から項目特性を推定する方法論が研究されている．
% 古典的な方法論としては，問題文を入力として項目特性値を出力する機械学習モデルを教師あり学習の枠組みで構築する手法が研究されてきた\cite{devlin2018bert,benedetto2023quantitative}．
% しかしこの方法では，モデル訓練のために特性値が既知の項目を大量に用意する必要があり，そのような項目集合を作るために，目的の学習領域に関する大量の項目を目標とする受験者集団に出題して事前に解かせる必要があった．このような方法論は，大規模かつ長期間運用されてきた試験や学習支援システム以外では実現が困難であり，活用可能な場面が限定的であった

% これとは異なる方法論として，近年では，自然言語処理技術の一つである質問応答システムを応用して人間受験者の項目反応を模倣する「仮想受験者」と呼ぶ技術が提案されている\cite{tomikawa2024adaptive,uto2024question,benedetto-etal-2024-using}．
% 例えば，性能の異なる多様な大規模言語モデル(Large Language Models)を用いて構築した質問応答システム群を仮想受験者集団とみなす手法が提案されている\cite{tomikawa2024adaptive}．
% この方法では，人間受験者の項目反応や特性が既知の項目データセットを利用せずに，仮想受験者を構築できるが，仮想受験者と人間受験者の反応傾向が一致する保証はない．
% 他方で，過去の項目群に対する人間受験者の反応データを用いて質問応答システムを訓練することで仮想受験者を構築する手法も提案されている\cite{uto2024question}．
% この方法では，人間受験者の項目反応を模倣させやすい一方で，古典的な方法論と同様に，人間受験者の反応データの収集に多大なコストを要する．

% これらの問題に対処できる仮想受験者の実現方法の一つとして，Benedetto et al.\cite{benedetto-etal-2024-using}は，LLMへのプロンプトとして，問題文と共に想定する受験者の特徴を与えることで，ゼロショットで受験者反応を模倣する手法を提案している．しかし，従来手法では，プロンプトに与える受験者の特徴が少数段階の能力レベルの指示のみに留まっており，細やかな知識状態の違いを模倣できていない．さらに，従来手法では，LLMによっては，適切に受験者レベルの調整ができないことを示している．これらはいずれも，プロンプトで与える受験者のプロフィールが荒いことに起因すると考えられる．

% これらの問題を解決するために，本研究では，個別の受験者がどのような知識・技能を持っているかの詳細な定義を受験者プロフィールとして記述し，その情報をプロンプトとして与えることで，より精密に目標の受験者の反応を予測できる擬似受験者手法を提案する．具体的には，英語の読解力テストを対象に，ヨーロッパ言語共通参照枠（Common
% European Framework of Reference for Languages: CEFR）に基づくA1からC2の各受験者レベルに対応する受験者プロフィールをCEFR Can-Do Statementを参考に設計して，プロンプトに含めることで，狙った知識・技能を持つ受験者の項目反応をより高精度に模倣することを目指す．

% 本研究では，実データ実験を通して提案モデルの有効性を示す．

\section{関連研究}

この章では，直接の先行研究であるBenedetto et al.\cite{benedetto-etal-2024-using}の研究を目的，方法，結果と課題を述べ，課題に関連する暗黙の前提や仮説に言及することで本研究で取り組む課題を焦点化する．

\subsection{先行研究の基本的な考え方}

この節では，先行研究の，研究背景と課題に対するアプローチ（仮説）と提案手法による改善点を述べることで，LLM仮想受験者モデルがどんな役割をはたし，後述の評価指標や結果の妥当性の理解を助ける．

\subsection{先行研究における評価の観点}

この節では，先行研究で用いられた評価指標がどのような観点で設計されており，それが先行研究のどのような新規性を担保しているのか示す．
同時に，よいLLM仮想受験者モデルの定義について足がかりとする．

\subsection{先行研究の結果と暗黙の前提}

この節では，先行研究の実験結果を述べ，先行研究で浮き彫りになった課題とその背景にある暗黙の前提や仮説を示す．

\subsection{先行研究の結果に基づく本研究が扱う課題の位置付け}

この節では，英語の読解問題を対象として，先行研究の結果が示す課題や暗黙の前提・仮説に対して本研究でどのようにアプローチしたかの連続性を明確化する．

% 本研究では，Benedetto et al.\cite{benedetto-etal-2024-using}が提案したLLMに基づくゼロショット型の仮想受験者手法を基礎とするため，ここではこの手法を説明する．
% この手法では，GPT-3.5やGPT-4などのLLMに対して特定の受験者レベル（1〜5の5段階）の受験者として振る舞うよう指示するプロンプトを与えることで，多肢選択問題への回答を生成させる．
% LLMへの入力は目的とする受験者レベルと対象とする項目の問題文と選択肢のテキスト，および出力形式に関わる指示と読解問題の場合は読解パッセージから構成される．
% 出力指示では正当選択肢のインデックスに加え，項目の難易度レベルと回答プロセスの根拠説明（指定された受験者レベルが当該問題で辿る思考過程や誤解の説明）を出力させるようにしている．

% 先行研究では，LLMが目的の受験者レベルに適した正答率分布を再現できるように，プロンプトエンジニアリングによる最適化を行っている．
% 具体的には，まず，5つの受験者レベルをそれぞれ指定したときの項目正答率をそれぞれ$a_1, a_2, a_3, a_4, a_5$（$a_i$はレベル$i$を指定した時の全項目にわたる正解率を意味する）とするとき，ベクトル$L = (a_1, a_2, a_3, a_4, a_5)$と理想的な正答率$I = (0.0, 0.25, 0.5, 0.75, 1.0)$ とのピアソン相関係数$\rho_{L,I}$を算出する．
% さらに，正答率の非単調性に対するペナルティ$P$を以下の式で計算する．

% \begin{equation}
% P = \sum_{i=1}^{4} \sqrt{|a_{i+1} - a_i|} \cdot I(a_{i+1} < a_i)
% \end{equation}

% \noindent ここで，$I(a_{i+1} < a_i)$は$a_{i+1} < a_i$の場合に1，そうでなければ0となる指示関数である．
% そして，最終的な評価指標M を次式で計算し，これが最大化されるようにプロンプトの最適化を行なっている．

% \begin{equation}
% M = \rho_{L,I} - P
% \end{equation}

% この研究では，仮想受験者モデルの最終的な性能評価を，以下の二つの観点で行なっている．
% \begin{enumerate}
% \item 単調増加性：指定した受験者レベルの上昇に伴い正答率が単調増加するか．
% \item 難易度依存性：同一の受験者レベルを指定した場合，問題の難易度増加で正答率が低下するか．
% \end{enumerate}

% 実験では，GPT-3.5をベースモデルとして用いた場合には単調増加性が確認されたが，他のモデルでは単調増加性が損なわれることが確認された．
% この要因の一つとして，従来手法では，仮想受験者の受験者レベルが1から5の数値のみで記述されており，受験者プロフィールが荒いことが考えられる．
% レベルに対応する詳細な知識状態などが表現されていないため，狙った項目反応を再現できていない可能性がある．

\section{提案手法}

この章では，前章までに示した研究背景と課題，先行研究の焦点化した課題に対して，本研究がどのような仮説とアプローチに基づき改善を試みたかを構造的に示す．

\subsection{提案手法の概要}

この節では，英語の読解問題を対象として先行研究の課題のうち強いモデルにおいて受験者反応をうまく模倣できない課題に対して，受験者プロフィールを具体的に精緻に設定し，プロンプトに含めることで模倣精度を改善させるアプローチを提案することを示す．

\subsection{受験者プロフィール設計の考え方}

この節では，英語の読解問題における受験者プロフィールの改善アプローチに対して，CEFRを客観的な基準として用い，肯定的な振る舞い定義，否定的な振る舞い定義と語彙力という観点でA1からC2の6段階に詳細化することで，模倣精度の改善を目指したことを示す．

\subsection{評価方針の設計（本研究における評価の考え方（Why/What））}

この節では，LLM仮想受験者の人間受験者反応の模倣精度について，2つの軸（難易度方向の正答率変化，受験者レベル方向正答率変化）によって本アプローチの有効性を評価することを示す．
あわせて，評価軸ごとに用いる評価指標の概要を示す．

% 上記の問題を解決するために，本研究では，個別の受験者がどのような知識・技能を持っているかの詳細な定義を受験者プロフィールとして記述し，その情報をプロンプトとして与えることで，より精密に目標の受験者の反応を予測できる擬似受験者手法を提案する．提案手法では，英語の読解力テストを対象に，ヨーロッパ言語共通参照枠（Common European Framework of Reference for Languages: CEFR）に基づくA1 からC2の各受験者レベルに対応する受験者プロフィールをCEFR Can-Do Statement を参考に設計して，プロンプトに含める．
% 具体的には，CEFR Global Scale のA1からC2に対応したCan-Do Descriptorから，それぞれのレベルの受験者が運用可能な語彙や文法・語法の知識，読解時の認知的振る舞いなどの一覧を取得し，それを受験者の知識状態プロフィール（受験者プロフィールと呼ぶ）として文字列化して，LLMへの入力プロンプトに組み込む．さらにプロンプトでは，当該レベルよりも上位のレベルに相当する知識や振る舞いをしないように指示する．

\section{実験}

この章では，前章までに示した課題とその改善アプローチに基づき，実際にどのような実験を行ったか説明し，その結果を示すことで，アプローチの有効性がどの程度であったか，どの辺りに限界があるかを示す．

\subsection{実験の目的と検証観点}

この節では，前章までに示した，課題，解決アプローチの有効性を示す目的のもと，どのような観点でその有効性を検証しようとしたかを示す

\subsection{実験設定の概要}

この節では，実験の目的と検証観点を踏まえて，具体的な実験をどのように組み立てたか，要素ごとに説明することで，実験によって目的や検証観点が適切に検証されるような設定になっていることを示す．

\subsection{評価指標と算出方法（Howに答える）}

この節では，前節までに示した研究アプローチと示したい有効性の観点を，どのように評価指標に落とし込んだか説明することで，実験の目的と評価指標の妥当性について明確化する．

\subsection{実験結果}

この節では，前節までに示した課題，解決アプローチ，具体的な実験設定，評価指標に基づき，実際に実施した実験の結果を構造的に示すことで，実験結果として本アプローチに限界があると示唆されたことを明示する．

% 現在までには，実データを用いて従来手法の再現実験を行った．

% 実データとしては，英語読解問題の多肢選択式問題データセットとして様々な言語処理研究でベンチマークデータとして利用されるRACEデータセットを用いた．
% RACEの各問題には3つの大まかな難易度レベル（middle, high, college）が割り当てられており，これをもとに難易度依存性の観点が分析できる．
% 本実験では，先行研究と同様に，層化サンプリングによって得られた，難易度レベルごとに50問ずつ，累計150問のデータを用いた．

% この150問を，提案手法と同様にA1からC2までの6段階の受験者レベルをそれぞれ指定した従来手法に解かせ，その平均正答率を算出した．ベースとなるLLMとしては，先行研究で用いられたgpt-3.5-turbo-0613の提供が終了していたため，より新しいgpt-3.5-turbo-1106 を使用した．さらに，より新しいLLMとして，GPT-4o-miniを利用する実験も行った．

% 提案手法の実験結果を図\ref{fig:gpt-3-5}と\ref{fig:gpt-4o-mini}に示す．
% 図\ref{fig:gpt-3-5}および図\ref{fig:gpt-4o-mini}は，それぞれgpt-3.5-turbo-1106 とgpt-4o-mini の項目難易度別・受験者レベル別の正答率をサブプロットとして示している．
% 縦軸は正答率，横軸は指定した受験者レベル，各領域は項目難易度を表す．
% 図\ref{fig:gpt-3-5}より，難易度依存性は概ね確認できるが，指定した受験者レベルの増加と正答率に部分的な齟齬が生じており，単調増加性の破綻が再現された．これは，図2で示したgpt-4o-miniの場合により顕著であることがわかる．このことから，先行研究でも報告されているように，先行研究のプロンプトでは，必ずしも合理的な挙動を示さないことが確認された．
% \begin{figure}[t]
% \centering
% \makebox[\columnwidth][c]{%
% \includegraphics[width=\columnwidth]{img/gpt_3_5_1106/60_accuracy_per_difficulty_with_different_roleplayed_levels.eps}%
% }
% \vspace{2mm}
% \caption{GPT-3.5-turbo-1106による難易度別正答率}
% \label{fig:gpt-3-5}
% \end{figure}

% \begin{figure}[t]
% \centering
% \makebox[\columnwidth][c]{%
% \includegraphics[width=\columnwidth]{img/gpt_4o_mini/68_accuracy_per_difficulty_with_different_roleplayed_levels.eps}%
% }
% \vspace{2mm}
% \caption{GPT-4o-miniによる難易度別正答率}
% \label{fig:gpt-4o-mini}
% \end{figure}

\section{まとめ}

この章では，これまでの一連の流れを簡単に振り返り，結論を述べることで，研究の全体像と意義を明確化する．

\subsection{本研究で明らかになったこと}

この節では，これまでの一連の流れを踏まえた上で，なにが分かったのかの連続性を示す．

\subsection{本研究の貢献と意義}

この節では，結果を含む本研究の全体像からどのような学術的貢献や意義があったか明示する．

\subsection{本研究の限界と今後の課題}

この節では，本研究の全体像を踏まえて，提案したアプローチの限界について述べる．

% 本研究では，LLMを用いた仮想受験者モデルの精度向上のため，CEFR Can-Do Statementに基づく詳細な受験者プロフィールをプロンプトに追加する手法を提案した．
% 現時点では，先行研究の再現実験を行い，従来手法が必ずしも指定した受験者レベルに応じた項目反応を保証しないことが確認された．今後は提案手法の実装を行い，従来手法との比較を通して有効性を評価していく．

{\small
\begin{thebibliography}{99}
\bibitem{devlin2018bert} J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, ``BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", arXiv preprint arXiv:1810.04805, 2018.
\bibitem{benedetto2023quantitative} L. Benedetto, ``A quantitative study of NLP approaches to question difficulty estimation", Proceedings of the International Conference on Artificial Intelligence in Education, pp.428--434, 2023.
\bibitem{tomikawa2024adaptive} Y. Tomikawa, A. Suzuki, M. Uto, ``Adaptive Question–Answer Generation With Difficulty Control Using Item Response Theory and Pretrained Transformer Models", IEEE Transactions on Learning Technologies, Vol.17, pp.2186--2198, 2024.

\bibitem{uto2024question} M. Uto, Y. Tomikawa, A. Suzuki, ``Question Difficulty Prediction Based on Virtual Test-Takers and Item Response Theory", AIED'24: Workshop on Automatic Evaluation of Learning and Assessment Content, pp.1--11, 2024.
\bibitem{benedetto-etal-2024-using} L. Benedetto, G. Aradelli, A. Donvito, A. Lucchetti, A. Cappelli, P. Buttery, ``Using LLMs to simulate students' responses to exam questions", Findings of the Association for Computational Linguistics: EMNLP 2024, pp.11351--11368, 2024.
\end{thebibliography}
}
\end{document}
